import cv2
import numpy as np
import time
import threading
import tkinter as tk
from tkinter import ttk, messagebox
import pygame
from datetime import datetime
import json
import os
from PIL import Image, ImageTk

class OptimizedPhoneDetector:
    def __init__(self):
        # OpenCV cascades
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        
        # Las cascadas de manos no est√°n incluidas en OpenCV por defecto
        self.hand_detection_available = False
        print("INFO: Usando detecci√≥n de regiones de manos basada en movimiento")
        
        # Variables de detecci√≥n
        self.cap = None
        self.is_monitoring = False
        self.detection_start_time = None
        self.last_frame = None
        self.current_frame = None
        self.show_camera = False
        
        # Configuraci√≥n optimizada
        self.config = {
            'alert_time': 20,
            'face_sensitivity': 1.1,
            'motion_sensitivity': 3000,
            'min_face_size': (50, 50),
            'phone_distance_threshold': 180,
            'phone_min_area': 1500,
            'phone_max_area': 80000,
            'canny_low': 30,
            'canny_high': 100,
            'hand_region_factor': 1.5,  # Factor para regi√≥n de b√∫squeda de manos
            'min_contour_solidity': 0.3  # Solidez m√≠nima para objetos v√°lidos
        }
        
        # Estad√≠sticas
        self.stats = {
            'total_usage_today': 0,
            'sessions': [],
            'alerts_triggered': 0
        }
        
        # Debug info
        self.debug_info = "Inicializando..."
        self.detection_data = {
            'faces_count': 0,
            'phone_candidates': 0,
            'hand_regions': 0,
            'motion_level': 0
        }
        
        # Inicializar pygame
        try:
            pygame.mixer.init()
        except:
            print("WARNING: Pygame no disponible")
        
        # GUI
        self.setup_gui()
        self.load_stats()
        self.detect_available_cameras()
    
    def detect_available_cameras(self):
        """Detectar c√°maras disponibles"""
        print("Detectando c√°maras disponibles...")
        self.available_cameras = []
        
        # Probar diferentes backends
        backends = [
            (cv2.CAP_DSHOW, "DirectShow"),
            (cv2.CAP_MSMF, "Media Foundation"),
            (cv2.CAP_ANY, "Auto")
        ]
        
        for idx in range(3):
            for backend_id, backend_name in backends:
                try:
                    cap = cv2.VideoCapture(idx, backend_id)
                    if cap.isOpened():
                        ret, frame = cap.read()
                        if ret and frame is not None:
                            width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
                            height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
                            self.available_cameras.append({
                                'index': idx,
                                'backend': backend_name,
                                'resolution': f"{int(width)}x{int(height)}"
                            })
                            print(f"‚úÖ C√°mara {idx}: {backend_name} - {int(width)}x{int(height)}")
                            cap.release()
                            break
                    cap.release()
                except Exception as e:
                    if cap:
                        cap.release()
                    continue
        
        if not self.available_cameras:
            print("‚ö†Ô∏è No se detectaron c√°maras funcionales")
            # Agregar c√°mara por defecto para intentar
            self.available_cameras.append({
                'index': 0,
                'backend': 'Default',
                'resolution': '640x480'
            })
        else:
            print(f"üìπ Total de c√°maras detectadas: {len(self.available_cameras)}")
    
    def setup_gui(self):
        self.root = tk.Tk()
        self.root.title("üì± Detector Optimizado - Sin MediaPipe")
        self.root.geometry("850x950")
        self.root.configure(bg='#1a1a1a')
        
        # Frame principal
        main_frame = tk.Frame(self.root, bg='#1a1a1a')
        main_frame.pack(fill='both', expand=True, padx=15, pady=15)
        
        # T√≠tulo
        title_frame = tk.Frame(main_frame, bg='#2d3748', relief='raised', bd=2)
        title_frame.pack(fill='x', pady=(0, 15))
        
        tk.Label(title_frame, text="üì± Detector Optimizado de Celular", 
                font=('Arial', 18, 'bold'), bg='#2d3748', fg='#fff').pack(pady=15)
        
        tk.Label(title_frame, text="Detecci√≥n avanzada con OpenCV + Vista en tiempo real", 
                font=('Arial', 11), bg='#2d3748', fg='#a0aec0').pack(pady=(0, 15))
        
        # Frame principal dividido
        content_frame = tk.Frame(main_frame, bg='#1a1a1a')
        content_frame.pack(fill='both', expand=True)
        
        # Panel izquierdo - C√°mara
        camera_panel = tk.Frame(content_frame, bg='#2d3748', relief='raised', bd=2)
        camera_panel.pack(side='left', fill='both', expand=True, padx=(0, 10))
        
        tk.Label(camera_panel, text="üìπ Vista en Tiempo Real", 
                font=('Arial', 14, 'bold'), bg='#2d3748', fg='#fff').pack(pady=10)
        
        self.camera_label = tk.Label(camera_panel, text="C√°mara desconectada\n\nHaz clic en 'Mostrar C√°mara'\npara ver la detecci√≥n", 
                                   bg='#1a202c', fg='#718096', font=('Arial', 11),
                                   width=40, height=20, relief='sunken', bd=2)
        self.camera_label.pack(pady=10, padx=10, fill='both', expand=True)
        
        # Controles de c√°mara
        camera_controls = tk.Frame(camera_panel, bg='#2d3748')
        camera_controls.pack(pady=10)
        
        self.toggle_camera_button = tk.Button(camera_controls, text="üìπ Mostrar C√°mara", 
                                            command=self.toggle_camera_view, 
                                            bg='#4299e1', fg='white', font=('Arial', 11, 'bold'),
                                            padx=20, pady=8)
        self.toggle_camera_button.pack()
        
        # Panel derecho - Controles y estado
        control_panel = tk.Frame(content_frame, bg='#2d3748', relief='raised', bd=2)
        control_panel.pack(side='right', fill='y', padx=(10, 0))
        
        # Estado
        status_frame = tk.LabelFrame(control_panel, text="üìä Estado del Sistema", 
                                   bg='#2d3748', fg='#fff', font=('Arial', 12, 'bold'))
        status_frame.pack(fill='x', padx=10, pady=10)
        
        self.status_label = tk.Label(status_frame, text="Estado: Detenido", 
                                   font=('Arial', 12, 'bold'), bg='#2d3748', fg='#4299e1')
        self.status_label.pack(pady=5)
        
        self.timer_label = tk.Label(status_frame, text="Tiempo: 00:00", 
                                  font=('Arial', 11), bg='#2d3748', fg='#fff')
        self.timer_label.pack(pady=2)
        
        self.detection_label = tk.Label(status_frame, text="M√©todo: Optimizado", 
                                      font=('Arial', 10), bg='#2d3748', fg='#a0aec0')
        self.detection_label.pack(pady=2)
        
        # Info de detecci√≥n en tiempo real
        detection_info_frame = tk.LabelFrame(control_panel, text="üîç Detecci√≥n en Tiempo Real", 
                                           bg='#2d3748', fg='#fff', font=('Arial', 11, 'bold'))
        detection_info_frame.pack(fill='x', padx=10, pady=5)
        
        self.faces_label = tk.Label(detection_info_frame, text="üë§ Caras: 0", 
                                  font=('Arial', 10), bg='#2d3748', fg='#68d391')
        self.faces_label.pack(anchor='w', padx=5, pady=2)
        
        self.phones_label = tk.Label(detection_info_frame, text="üì± Celulares: 0", 
                                   font=('Arial', 10), bg='#2d3748', fg='#f6ad55')
        self.phones_label.pack(anchor='w', padx=5, pady=2)
        
        self.hands_label = tk.Label(detection_info_frame, text="üñêÔ∏è Regiones mano: 0", 
                                  font=('Arial', 10), bg='#2d3748', fg='#9f7aea')
        self.hands_label.pack(anchor='w', padx=5, pady=2)
        
        self.motion_label = tk.Label(detection_info_frame, text="üèÉ Movimiento: 0%", 
                                   font=('Arial', 10), bg='#2d3748', fg='#63b3ed')
        self.motion_label.pack(anchor='w', padx=5, pady=2)
        
        # Controles principales
        controls_frame = tk.LabelFrame(control_panel, text="üéÆ Controles", 
                                     bg='#2d3748', fg='#fff', font=('Arial', 12, 'bold'))
        controls_frame.pack(fill='x', padx=10, pady=10)
        
        self.start_button = tk.Button(controls_frame, text="‚ñ∂Ô∏è INICIAR DETECCI√ìN", 
                                    command=self.start_monitoring, 
                                    bg='#48bb78', fg='white', font=('Arial', 12, 'bold'),
                                    padx=20, pady=10)
        self.start_button.pack(fill='x', padx=10, pady=5)
        
        self.stop_button = tk.Button(controls_frame, text="‚èπÔ∏è DETENER", 
                                   command=self.stop_monitoring, 
                                   bg='#f56565', fg='white', font=('Arial', 12, 'bold'),
                                   padx=20, pady=10, state='disabled')
        self.stop_button.pack(fill='x', padx=10, pady=5)
        
        # Configuraci√≥n
        config_frame = tk.LabelFrame(control_panel, text="‚öôÔ∏è Configuraci√≥n", 
                                   bg='#2d3748', fg='#fff', font=('Arial', 11, 'bold'))
        config_frame.pack(fill='x', padx=10, pady=10)
        
        # Tiempo de alerta
        tk.Label(config_frame, text="‚è∞ Tiempo alerta (seg):", 
                bg='#2d3748', fg='#fff', font=('Arial', 10)).pack(anchor='w', padx=5)
        
        self.alert_time_var = tk.IntVar(value=self.config['alert_time'])
        alert_scale = tk.Scale(config_frame, from_=5, to=120, orient='horizontal', 
                             variable=self.alert_time_var, bg='#4a5568', fg='white',
                             highlightbackground='#2d3748', length=200)
        alert_scale.pack(fill='x', padx=5, pady=2)
        
        # Sensibilidad
        tk.Label(config_frame, text="üì± Distancia m√°xima:", 
                bg='#2d3748', fg='#fff', font=('Arial', 10)).pack(anchor='w', padx=5)
        
        self.phone_distance_var = tk.IntVar(value=self.config['phone_distance_threshold'])
        distance_scale = tk.Scale(config_frame, from_=80, to=300, orient='horizontal',
                                variable=self.phone_distance_var, bg='#4a5568', fg='white',
                                highlightbackground='#2d3748', length=200)
        distance_scale.pack(fill='x', padx=5, pady=2)
        
        # M√©todo de detecci√≥n
        method_frame = tk.LabelFrame(control_panel, text="üîç M√©todo de Detecci√≥n", 
                                   bg='#2d3748', fg='#fff', font=('Arial', 11, 'bold'))
        method_frame.pack(fill='x', padx=10, pady=10)
        
        self.detection_method = tk.StringVar(value="shapes_only")
        
        methods = [
            ("üì± Solo Formas (RECOMENDADO)", "shapes_only"),
            ("üñêÔ∏è Solo Manos", "hands_only"),
            ("üèÉ Solo Movimiento", "motion_only"),
            ("üéØ Inteligente Flexible", "intelligent_flexible"),
            ("üë§ Solo detecci√≥n facial", "face_only")
        ]
        
        for text, value in methods:
            tk.Radiobutton(method_frame, text=text, variable=self.detection_method, value=value,
                          bg='#2d3748', fg='white', selectcolor='#4a5568',
                          font=('Arial', 9)).pack(anchor='w', padx=5)
        
        # Estad√≠sticas
        stats_frame = tk.LabelFrame(control_panel, text="üìä Estad√≠sticas Hoy", 
                                  bg='#2d3748', fg='#fff', font=('Arial', 11, 'bold'))
        stats_frame.pack(fill='x', padx=10, pady=10)
        
        self.usage_today_label = tk.Label(stats_frame, text="üì± Uso total: 0 min", 
                                        bg='#2d3748', fg='#4299e1', font=('Arial', 10))
        self.usage_today_label.pack(anchor='w', padx=5, pady=2)
        
        self.sessions_label = tk.Label(stats_frame, text="üìÖ Sesiones: 0", 
                                     bg='#2d3748', fg='#4299e1', font=('Arial', 10))
        self.sessions_label.pack(anchor='w', padx=5, pady=2)
        
        self.alerts_label = tk.Label(stats_frame, text="üö® Alertas: 0", 
                                   bg='#2d3748', fg='#f56565', font=('Arial', 10))
        self.alerts_label.pack(anchor='w', padx=5, pady=2)
        
        # Informaci√≥n
        info_frame = tk.Frame(main_frame, bg='#2a4365', relief='raised', bd=1)
        info_frame.pack(fill='x', pady=(15, 0))
        
        info_text = """üí° DETECTOR OPTIMIZADO SIN MEDIAPIPE
‚Ä¢ Detecci√≥n inteligente de formas rectangulares (celulares)
‚Ä¢ An√°lisis de regiones de manos basado en posici√≥n facial
‚Ä¢ Vista en tiempo real con visualizaci√≥n de detecci√≥n
‚Ä¢ Configuraci√≥n de sensibilidad en tiempo real
‚Ä¢ Compatible con cualquier versi√≥n de Python"""
        
        tk.Label(info_frame, text=info_text, bg='#2a4365', fg='#e2e8f0',
                font=('Arial', 9), justify='left').pack(padx=15, pady=10)
    
    def toggle_camera_view(self):
        """Alternar vista de c√°mara"""
        self.show_camera = not self.show_camera
        if self.show_camera:
            self.toggle_camera_button.config(text="üìπ Ocultar C√°mara", bg='#e53e3e')
        else:
            self.toggle_camera_button.config(text="üìπ Mostrar C√°mara", bg='#4299e1')
            self.camera_label.config(image='', text="Vista de c√°mara oculta\n\nHaz clic en 'Mostrar C√°mara'\npara activar")
    
    def start_monitoring(self):
        """Iniciar monitoreo"""
        try:
            # Probar c√°maras detectadas con sus backends
            self.cap = None
            
            for camera_info in self.available_cameras:
                idx = camera_info['index']
                backend_name = camera_info.get('backend', 'Default')
                print(f"Probando c√°mara {idx} ({backend_name})...")
                
                # Mapear backends
                backend_map = {
                    "DirectShow": cv2.CAP_DSHOW,
                    "Media Foundation": cv2.CAP_MSMF,
                    "Auto": cv2.CAP_ANY,
                    "Default": cv2.CAP_ANY
                }
                
                backend_id = backend_map.get(backend_name, cv2.CAP_ANY)
                
                try:
                    test_cap = cv2.VideoCapture(idx, backend_id)
                    
                    if test_cap.isOpened():
                        ret, frame = test_cap.read()
                        if ret and frame is not None:
                            self.cap = test_cap
                            print(f"‚úÖ C√°mara {idx} funcionando con {backend_name}")
                            break
                        else:
                            test_cap.release()
                    else:
                        test_cap.release()
                except Exception as e:
                    print(f"‚ùå Error probando c√°mara {idx}: {e}")
                    if 'test_cap' in locals():
                        test_cap.release()
                    continue
            
            if not self.cap:
                # √öltimo intento b√°sico
                print("üîÑ √öltimo intento con c√°mara por defecto...")
                try:
                    self.cap = cv2.VideoCapture(0)
                    if not self.cap.isOpened():
                        raise Exception("No se pudo abrir c√°mara 0")
                    
                    ret, frame = self.cap.read()
                    if not ret:
                        self.cap.release()
                        raise Exception("No se pudo leer de la c√°mara")
                        
                    print("‚úÖ C√°mara por defecto funcionando")
                except Exception as e:
                    messagebox.showerror("‚ùå Error de C√°mara", 
                                       f"No se pudo acceder a ninguna c√°mara.\n\nError: {str(e)}\n\nVerifica que:\n‚Ä¢ La c√°mara est√© conectada\n‚Ä¢ No est√© siendo usada por otra app\n‚Ä¢ Tengas permisos de c√°mara")
                    return
            
            # Configurar c√°mara
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.cap.set(cv2.CAP_PROP_FPS, 20)
            
            self.is_monitoring = True
            self.detection_start_time = None
            self.last_frame = None
            
            # UI
            self.start_button.config(state='disabled')
            self.stop_button.config(state='normal')
            self.status_label.config(text="Estado: üîÑ Iniciando...", fg='#f6ad55')
            
            # Activar c√°mara autom√°ticamente
            self.show_camera = True
            self.toggle_camera_button.config(text="üìπ Ocultar C√°mara", bg='#e53e3e')
            
            # Iniciar hilo
            self.detection_thread = threading.Thread(target=self.detection_loop, daemon=True)
            self.detection_thread.start()
            
            self.update_ui()
            print("OK: Monitoreo iniciado")
            
        except Exception as e:
            messagebox.showerror("Error", f"Error al iniciar: {str(e)}")
    
    def stop_monitoring(self):
        """Detener monitoreo"""
        self.is_monitoring = False
        
        if self.cap:
            self.cap.release()
        
        if self.detection_start_time:
            self.end_session()
        
        self.start_button.config(state='normal')
        self.stop_button.config(state='disabled')
        self.status_label.config(text="Estado: ‚èπÔ∏è Detenido", fg='#a0aec0')
        self.timer_label.config(text="Tiempo: 00:00")
        self.camera_label.config(image='', text="C√°mara desconectada")
        
        print("Monitoreo detenido")
    
    def detection_loop(self):
        """Bucle principal optimizado"""
        consecutive_errors = 0
        max_errors = 10
        
        while self.is_monitoring:
            try:
                ret, frame = self.cap.read()
                if not ret:
                    consecutive_errors += 1
                    if consecutive_errors >= max_errors:
                        break
                    time.sleep(0.1)
                    continue
                
                consecutive_errors = 0
                frame = cv2.flip(frame, 1)
                self.current_frame = frame.copy()
                
                # Detectar seg√∫n m√©todo
                detected = False
                method = self.detection_method.get()
                
                if method == "face_only":
                    detected = self.detect_face(frame)
                    
                elif method == "motion_only":
                    detected = self.detect_motion(frame)
                    
                elif method == "shapes_only":
                    detected = self.detect_phone_shapes_advanced(frame)
                    
                elif method == "hands_only":
                    detected = self.detect_hands_optimized(frame)
                    
                elif method == "intelligent_flexible":
                    detected = self.intelligent_detection_flexible(frame)
                    
                else:  # intelligent (legacy)
                    detected = self.intelligent_detection(frame)
                
                self.process_detection(detected)
                self.update_camera_display(frame)
                
                # Guardar frame para movimiento
                self.last_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                time.sleep(0.05)
                
            except Exception as e:
                print(f"ERROR: {e}")
                time.sleep(1)
    
    def detect_face(self, frame):
        """Detectar rostros mejorado"""
        try:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # Aplicar ecualizaci√≥n de histograma para mejor detecci√≥n
            gray = cv2.equalizeHist(gray)
            
            faces = self.face_cascade.detectMultiScale(
                gray,
                scaleFactor=self.config['face_sensitivity'],
                minNeighbors=5,
                minSize=self.config['min_face_size'],
                maxSize=(300, 300)
            )
            
            self.detection_data['faces_count'] = len(faces)
            return len(faces) > 0
            
        except Exception as e:
            print(f"ERROR face detection: {e}")
            return False
    
    def detect_motion(self, frame):
        """Detectar movimiento optimizado"""
        try:
            if self.last_frame is None:
                return False
            
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray, (21, 21), 0)
            
            diff = cv2.absdiff(self.last_frame, gray)
            _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)
            
            # Operaciones morfol√≥gicas para limpiar
            kernel = np.ones((5,5), np.uint8)
            thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)
            thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
            
            motion_pixels = cv2.countNonZero(thresh)
            motion_percentage = (motion_pixels / (frame.shape[0] * frame.shape[1])) * 100
            
            self.detection_data['motion_level'] = motion_percentage
            return motion_pixels > self.config['motion_sensitivity']
            
        except Exception as e:
            print(f"ERROR motion detection: {e}")
            return False
    
    def detect_phone_shapes_advanced(self, frame):
        """Detecci√≥n avanzada de formas rectangulares"""
        try:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # Preprocesamiento mejorado
            gray = cv2.bilateralFilter(gray, 9, 75, 75)
            
            # Detecci√≥n de bordes adaptativa
            edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                        cv2.THRESH_BINARY, 11, 2)
            
            # Tambi√©n usar Canny
            canny = cv2.Canny(gray, self.config['canny_low'], self.config['canny_high'])
            
            # Combinar ambos m√©todos
            combined = cv2.bitwise_or(edges, canny)
            
            # Operaciones morfol√≥gicas
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
            combined = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel)
            
            contours, _ = cv2.findContours(combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            phone_candidates = []
            
            for contour in contours:
                area = cv2.contourArea(contour)
                
                if area < self.config['phone_min_area'] or area > self.config['phone_max_area']:
                    continue
                
                # Calcular solidez (√°rea / √°rea del casco convexo)
                hull = cv2.convexHull(contour)
                hull_area = cv2.contourArea(hull)
                if hull_area == 0:
                    continue
                    
                solidity = area / hull_area
                
                if solidity < self.config['min_contour_solidity']:
                    continue
                
                # Aproximar a rect√°ngulo
                epsilon = 0.02 * cv2.arcLength(contour, True)
                approx = cv2.approxPolyDP(contour, epsilon, True)
                
                if len(approx) >= 4:
                    x, y, w, h = cv2.boundingRect(contour)
                    aspect_ratio = max(w, h) / min(w, h)
                    
                    # Proporci√≥n t√≠pica de celular m√°s flexible
                    if 1.2 <= aspect_ratio <= 3.5:
                        phone_candidates.append({
                            'x': x, 'y': y, 'w': w, 'h': h,
                            'area': area,
                            'aspect_ratio': aspect_ratio,
                            'solidity': solidity,
                            'center': (x + w//2, y + h//2)
                        })
            
            self.detection_data['phone_candidates'] = len(phone_candidates)
            return len(phone_candidates) > 0
            
        except Exception as e:
            print(f"ERROR shape detection: {e}")
            return False
    
    def detect_hand_regions(self, frame, faces):
        """Detectar regiones probables de manos basado en posici√≥n facial"""
        try:
            if len(faces) == 0:
                return []
            
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            hand_regions = []
            
            for (face_x, face_y, face_w, face_h) in faces:
                # Definir regiones donde probablemente est√©n las manos
                face_center_x = face_x + face_w // 2
                face_center_y = face_y + face_h // 2
                
                # Regiones t√≠picas de manos al usar celular
                regions = [
                    # Frente al rostro
                    (face_center_x - face_w//2, face_y - face_h//3, face_w, face_h//2),
                    # Lado derecho
                    (face_x + face_w, face_center_y - face_h//3, face_w//2, face_h//2),
                    # Lado izquierdo  
                    (face_x - face_w//2, face_center_y - face_h//3, face_w//2, face_h//2),
                ]
                
                for (rx, ry, rw, rh) in regions:
                    # Asegurar que la regi√≥n est√© dentro del frame
                    rx = max(0, rx)
                    ry = max(0, ry)
                    rw = min(rw, frame.shape[1] - rx)
                    rh = min(rh, frame.shape[0] - ry)
                    
                    if rw > 20 and rh > 20:
                        roi = gray[ry:ry+rh, rx:rx+rw]
                        
                        # Detectar movimiento en la regi√≥n
                        if hasattr(self, 'last_frame') and self.last_frame is not None:
                            last_roi = self.last_frame[ry:ry+rh, rx:rx+rw]
                            diff = cv2.absdiff(roi, last_roi)
                            _, thresh = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)
                            movement = cv2.countNonZero(thresh)
                            
                            # Si hay suficiente movimiento, considerar como posible mano
                            if movement > (rw * rh * 0.1):  # 10% de la regi√≥n
                                hand_regions.append({
                                    'x': rx, 'y': ry, 'w': rw, 'h': rh,
                                    'movement': movement,
                                    'center': (rx + rw//2, ry + rh//2)
                                })
            
            self.detection_data['hand_regions'] = len(hand_regions)
            return hand_regions
            
        except Exception as e:
            print(f"ERROR hand regions: {e}")
            return []
    
    def intelligent_detection(self, frame):
        """Detecci√≥n inteligente combinada"""
        try:
            # 1. Detectar rostros
            face_detected = self.detect_face(frame)
            
            if not face_detected:
                self.debug_info = "Sin rostros detectados"
                return False
            
            # 2. Obtener rostros para an√°lisis
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(
                gray, scaleFactor=self.config['face_sensitivity'],
                minNeighbors=5, minSize=self.config['min_face_size']
            )
            
            # 3. Detectar formas de celular
            phone_shapes = self.detect_phone_shapes_advanced(frame)
            
            # 4. Detectar regiones de manos
            hand_regions = self.detect_hand_regions(frame, faces)
            
            # 5. Verificar proximidad
            phone_near_face = False
            hands_near_face = False
            
            if phone_shapes:
                phone_near_face = self.check_proximity_to_face(frame, faces, "phone")
            
            if hand_regions:
                hands_near_face = self.check_proximity_to_face(frame, faces, "hands")
            
            # 6. L√≥gica de detecci√≥n inteligente
            # Detectar si hay rostro Y (celular cerca O manos activas cerca)
            detected = face_detected and (phone_near_face or hands_near_face)
            
            # Debug info
            self.debug_info = f"Cara:{'‚úì' if face_detected else '‚úó'} Celular:{'‚úì' if phone_near_face else '‚úó'} Manos:{'‚úì' if hands_near_face else '‚úó'}"
            
            return detected
            
        except Exception as e:
            print(f"ERROR intelligent detection: {e}")
            self.debug_info = f"Error: {str(e)[:30]}"
            return False
    
    def detect_hands_optimized(self, frame):
        """Detecci√≥n optimizada solo de manos"""
        try:
            # 1. Detectar rostros para definir regiones
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(
                gray, scaleFactor=self.config['face_sensitivity'],
                minNeighbors=5, minSize=self.config['min_face_size']
            )
            
            self.detection_data['faces_count'] = len(faces)
            
            # Si no hay rostros, usar regiones generales
            if len(faces) == 0:
                # Detectar movimiento en regiones t√≠picas de manos
                h, w = frame.shape[:2]
                general_regions = [
                    (w//4, h//4, w//2, h//2, "CENTRO"),
                    (0, h//3, w//3, h//3, "IZQUIERDA"),
                    (2*w//3, h//3, w//3, h//3, "DERECHA"),
                ]
                hand_activity = self.check_hand_activity_in_regions(frame, general_regions)
                self.debug_info = f"Sin rostro - Actividad manos: {hand_activity}"
                return hand_activity > 0
            
            # 2. Detectar actividad de manos en regiones faciales
            hand_regions = self.detect_hand_regions(frame, faces)
            hands_detected = len(hand_regions) > 0
            
            # 3. Tambi√©n verificar movimiento general en √°rea superior
            h, w = frame.shape[:2]
            upper_region_movement = self.detect_movement_in_region(frame, (0, 0, w, h//2))
            
            # 4. Combinar detecciones
            detected = hands_detected or upper_region_movement
            
            self.detection_data['hand_regions'] = len(hand_regions)
            self.debug_info = f"Manos: {len(hand_regions)} | Mov.superior: {'‚úì' if upper_region_movement else '‚úó'}"
            
            return detected
            
        except Exception as e:
            print(f"ERROR hands optimized: {e}")
            self.debug_info = f"Error manos: {str(e)[:20]}"
            return False
    
    def intelligent_detection_flexible(self, frame):
        """Detecci√≥n inteligente m√°s flexible - Cara O Manos"""
        try:
            # 1. Detectar rostros
            face_detected = self.detect_face(frame)
            
            # 2. Detectar manos
            hands_detected = self.detect_hands_optimized(frame)
            
            # 3. Detectar formas (opcional)
            phone_shapes = self.detect_phone_shapes_advanced(frame)
            
            # 4. L√≥gica flexible: Cara O Manos O (Formas y Movimiento)
            movement_detected = self.detect_motion(frame)
            
            detected = (face_detected or 
                       hands_detected or 
                       (phone_shapes and movement_detected))
            
            # Debug info
            self.debug_info = f"Cara:{'‚úì' if face_detected else '‚úó'} Manos:{'‚úì' if hands_detected else '‚úó'} Mov:{'‚úì' if movement_detected else '‚úó'}"
            
            return detected
            
        except Exception as e:
            print(f"ERROR flexible detection: {e}")
            self.debug_info = f"Error flex: {str(e)[:20]}"
            return False
    
    def check_hand_activity_in_regions(self, frame, regions):
        """Verificar actividad de manos en regiones espec√≠ficas"""
        try:
            if not hasattr(self, 'last_frame') or self.last_frame is None:
                return 0
            
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            active_regions = 0
            
            for (rx, ry, rw, rh, label) in regions:
                if rx + rw <= gray.shape[1] and ry + rh <= gray.shape[0]:
                    roi = gray[ry:ry+rh, rx:rx+rw]
                    last_roi = self.last_frame[ry:ry+rh, rx:rx+rw]
                    
                    diff = cv2.absdiff(roi, last_roi)
                    _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)
                    
                    # Aplicar filtros morfol√≥gicos para limpiar ruido
                    kernel = np.ones((3,3), np.uint8)
                    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)
                    
                    movement = cv2.countNonZero(thresh)
                    movement_percentage = (movement / (rw * rh)) * 100
                    
                    # Si hay suficiente movimiento (m√°s del 5%)
                    if movement_percentage > 5:
                        active_regions += 1
            
            return active_regions
            
        except Exception as e:
            print(f"ERROR hand activity: {e}")
            return 0
    
    def detect_movement_in_region(self, frame, region):
        """Detectar movimiento en regi√≥n espec√≠fica"""
        try:
            if not hasattr(self, 'last_frame') or self.last_frame is None:
                return False
            
            rx, ry, rw, rh = region
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # Asegurar que la regi√≥n est√© dentro del frame
            rx = max(0, rx)
            ry = max(0, ry)
            rw = min(rw, gray.shape[1] - rx)
            rh = min(rh, gray.shape[0] - ry)
            
            if rw <= 0 or rh <= 0:
                return False
            
            roi = gray[ry:ry+rh, rx:rx+rw]
            last_roi = self.last_frame[ry:ry+rh, rx:rx+rw]
            
            diff = cv2.absdiff(roi, last_roi)
            _, thresh = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)
            
            movement = cv2.countNonZero(thresh)
            movement_percentage = (movement / (rw * rh)) * 100
            
            return movement_percentage > 8  # 8% de la regi√≥n
            
        except Exception as e:
            print(f"ERROR movement region: {e}")
            return False
    
    def check_proximity_to_face(self, frame, faces, detection_type):
        """Verificar proximidad a la cara"""
        try:
            threshold = self.config['phone_distance_threshold']
            
            for (face_x, face_y, face_w, face_h) in faces:
                face_center = (face_x + face_w//2, face_y + face_h//2)
                
                if detection_type == "phone":
                    # Verificar candidatos de celular
                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                    # Reutilizar l√≥gica de detecci√≥n de formas
                    # (simplificado para este ejemplo)
                    return self.detection_data['phone_candidates'] > 0
                
                elif detection_type == "hands":
                    # Verificar regiones de manos
                    return self.detection_data['hand_regions'] > 0
            
            return False
            
        except Exception as e:
            print(f"ERROR proximity check: {e}")
            return False
    
    def update_camera_display(self, frame):
        """Actualizar display con visualizaciones"""
        if not self.show_camera:
            return
        
        try:
            display_frame = frame.copy()
            
            # Dibujar detecciones
            self.draw_face_detection(display_frame)
            self.draw_phone_detection(display_frame)
            self.draw_hand_regions(display_frame)
            self.draw_debug_overlay(display_frame)
            
            # Redimensionar
            display_frame = cv2.resize(display_frame, (400, 300))
            
            # Convertir a tkinter
            display_frame_rgb = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
            image = Image.fromarray(display_frame_rgb)
            photo = ImageTk.PhotoImage(image)
            
            self.camera_label.config(image=photo, text='')
            self.camera_label.image = photo
            
        except Exception as e:
            print(f"ERROR updating display: {e}")
    
    def draw_face_detection(self, frame):
        """Dibujar detecci√≥n de rostros"""
        try:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(
                gray, scaleFactor=self.config['face_sensitivity'],
                minNeighbors=5, minSize=self.config['min_face_size']
            )
            
            for (x, y, w, h) in faces:
                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 3)
                cv2.putText(frame, f'ROSTRO', (x, y-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
        except Exception as e:
            print(f"ERROR drawing faces: {e}")
    
    def draw_phone_detection(self, frame):
        """Dibujar detecci√≥n de celulares"""
        try:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.bilateralFilter(gray, 9, 75, 75)
            
            edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                        cv2.THRESH_BINARY, 11, 2)
            canny = cv2.Canny(gray, self.config['canny_low'], self.config['canny_high'])
            combined = cv2.bitwise_or(edges, canny)
            
            contours, _ = cv2.findContours(combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                area = cv2.contourArea(contour)
                
                if area < self.config['phone_min_area'] or area > self.config['phone_max_area']:
                    continue
                
                hull = cv2.convexHull(contour)
                hull_area = cv2.contourArea(hull)
                if hull_area == 0:
                    continue
                    
                solidity = area / hull_area
                if solidity < self.config['min_contour_solidity']:
                    continue
                
                epsilon = 0.02 * cv2.arcLength(contour, True)
                approx = cv2.approxPolyDP(contour, epsilon, True)
                
                if len(approx) >= 4:
                    x, y, w, h = cv2.boundingRect(contour)
                    aspect_ratio = max(w, h) / min(w, h)
                    
                    if 1.2 <= aspect_ratio <= 3.5:
                        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)
                        cv2.putText(frame, f'CELULAR {aspect_ratio:.1f}', (x, y-10), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
                
        except Exception as e:
            print(f"ERROR drawing phones: {e}")
    
    def draw_hand_regions(self, frame):
        """Dibujar regiones de manos"""
        try:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(
                gray, scaleFactor=self.config['face_sensitivity'],
                minNeighbors=5, minSize=self.config['min_face_size']
            )
            
            for (face_x, face_y, face_w, face_h) in faces:
                face_center_x = face_x + face_w // 2
                face_center_y = face_y + face_h // 2
                
                regions = [
                    (face_center_x - face_w//2, face_y - face_h//3, face_w, face_h//2, "FRENTE"),
                    (face_x + face_w, face_center_y - face_h//3, face_w//2, face_h//2, "DERECHA"),
                    (face_x - face_w//2, face_center_y - face_h//3, face_w//2, face_h//2, "IZQUIERDA"),
                ]
                
                for (rx, ry, rw, rh, label) in regions:
                    rx = max(0, rx)
                    ry = max(0, ry)
                    rw = min(rw, frame.shape[1] - rx)
                    rh = min(rh, frame.shape[0] - ry)
                    
                    if rw > 20 and rh > 20:
                        # Verificar actividad en la regi√≥n
                        if hasattr(self, 'last_frame') and self.last_frame is not None:
                            roi = gray[ry:ry+rh, rx:rx+rw]
                            last_roi = self.last_frame[ry:ry+rh, rx:rx+rw]
                            diff = cv2.absdiff(roi, last_roi)
                            _, thresh = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)
                            movement = cv2.countNonZero(thresh)
                            
                            if movement > (rw * rh * 0.1):
                                cv2.rectangle(frame, (rx, ry), (rx+rw, ry+rh), (255, 255, 0), 2)
                                cv2.putText(frame, f'MANO {label}', (rx, ry-5), 
                                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
                
        except Exception as e:
            print(f"ERROR drawing hands: {e}")
    
    def draw_debug_overlay(self, frame):
        """Dibujar informaci√≥n de debug"""
        try:
            h, w = frame.shape[:2]
            
            # Fondo para informaci√≥n
            overlay = frame.copy()
            cv2.rectangle(overlay, (10, 10), (w-10, 100), (0, 0, 0), -1)
            cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
            
            # Informaci√≥n de detecci√≥n
            y_offset = 30
            info_lines = [
                f"Metodo: {self.detection_method.get()}",
                f"Caras: {self.detection_data['faces_count']} | Celulares: {self.detection_data['phone_candidates']}",
                f"Regiones mano: {self.detection_data['hand_regions']} | Movimiento: {self.detection_data['motion_level']:.1f}%",
            ]
            
            for line in info_lines:
                cv2.putText(frame, line, (15, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                y_offset += 20
            
            # Estado de detecci√≥n
            if self.detection_start_time:
                elapsed = time.time() - self.detection_start_time
                cv2.putText(frame, f"DETECTADO: {elapsed:.1f}s", (15, h-20), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                
        except Exception as e:
            print(f"ERROR drawing debug: {e}")
    
    def process_detection(self, detected):
        """Procesar resultado de detecci√≥n"""
        current_time = time.time()
        
        if detected:
            if self.detection_start_time is None:
                self.detection_start_time = current_time
                print("Uso del celular detectado")
            
            elapsed_time = current_time - self.detection_start_time
            
            if elapsed_time >= self.alert_time_var.get():
                self.show_alert()
        else:
            if self.detection_start_time is not None:
                self.end_session()
    
    def end_session(self):
        """Finalizar sesi√≥n"""
        if self.detection_start_time:
            session_duration = time.time() - self.detection_start_time
            
            if session_duration > 2:
                self.stats['sessions'].append({
                    'start': datetime.fromtimestamp(self.detection_start_time).isoformat(),
                    'duration': session_duration
                })
                
                self.stats['total_usage_today'] += session_duration
                print(f"Sesi√≥n guardada: {session_duration:.1f}s")
            
            self.detection_start_time = None
            self.save_stats()
    
    def show_alert(self):
        """Mostrar alerta en pantalla completa"""
        self.stats['alerts_triggered'] += 1
        
        # Sonido m√°s fuerte
        try:
            import winsound
            # Beeps m√∫ltiples para llamar m√°s la atenci√≥n
            for _ in range(3):
                winsound.Beep(1000, 200)
                time.sleep(0.1)
        except:
            pass
        
        # Ventana en PANTALLA COMPLETA
        alert = tk.Toplevel(self.root)
        alert.title("üö® ALERTA DE CELULAR")
        
        # Configurar pantalla completa
        alert.attributes('-fullscreen', True)
        alert.attributes('-topmost', True)
        alert.configure(bg='#dc2626')  # Rojo m√°s intenso
        alert.grab_set()
        
        # Crear frame principal centrado
        main_frame = tk.Frame(alert, bg='#dc2626')
        main_frame.pack(expand=True, fill='both')
        
        # T√≠tulo gigante
        title_label = tk.Label(main_frame, text="üö® ¬°DEJA EL CELULAR! üö®", 
                              font=('Arial', 60, 'bold'), bg='#dc2626', fg='white')
        title_label.pack(pady=(100, 50))
        
        # Mensaje principal
        message_label = tk.Label(main_frame, 
                                text=f"Has estado usando el celular por {self.alert_time_var.get()} segundos", 
                                font=('Arial', 28), bg='#dc2626', fg='white')
        message_label.pack(pady=30)
        
        # Submensaje motivacional
        motivational_messages = [
            "Tus ojos necesitan un descanso",
            "Es momento de una pausa",
            "Tu bienestar es importante",
            "Desconecta para reconectar contigo",
            "Tu salud mental lo agradecer√°"
        ]
        import random
        submessage = random.choice(motivational_messages)
        
        sub_label = tk.Label(main_frame, text=submessage, 
                            font=('Arial', 20), bg='#dc2626', fg='#fecaca')
        sub_label.pack(pady=20)
        
        # Informaci√≥n del m√©todo de detecci√≥n
        method_info = {
            "hands_only": "Movimiento de manos detectado",
            "motion_only": "Actividad general detectada",
            "intelligent_flexible": "Detecci√≥n inteligente activada",
            "shapes_only": "Forma de celular detectada",
            "face_only": "Posici√≥n facial detectada"
        }
        
        current_method = self.detection_method.get()
        detection_info = method_info.get(current_method, "Sistema de detecci√≥n activado")
        
        detection_label = tk.Label(main_frame, text=f"‚Ä¢ {detection_info} ‚Ä¢", 
                                  font=('Arial', 16), bg='#dc2626', fg='#fca5a5')
        detection_label.pack(pady=15)
        
        # Contador regresivo visual
        countdown_label = tk.Label(main_frame, text="", 
                                  font=('Arial', 24, 'bold'), bg='#dc2626', fg='#fef2f2')
        countdown_label.pack(pady=20)
        
        # Frame de botones m√°s grande
        button_frame = tk.Frame(main_frame, bg='#dc2626')
        button_frame.pack(pady=50)
        
        # Bot√≥n principal m√°s grande
        ok_button = tk.Button(button_frame, text="‚úÖ ENTENDIDO - CERRAR", 
                             command=alert.destroy,
                             bg='white', fg='#dc2626', 
                             font=('Arial', 20, 'bold'),
                             padx=40, pady=20,
                             relief='raised', bd=5)
        ok_button.pack(side='left', padx=20)
        
        # Bot√≥n de snooze
        snooze_button = tk.Button(button_frame, text="‚è∞ 5 MINUTOS M√ÅS", 
                                 command=lambda: [setattr(self, 'detection_start_time', time.time()), alert.destroy()],
                                 bg='#991b1b', fg='white', 
                                 font=('Arial', 16, 'bold'),
                                 padx=30, pady=15,
                                 relief='raised', bd=3)
        snooze_button.pack(side='left', padx=20)
        
        # Informaci√≥n de escape
        escape_label = tk.Label(main_frame, text="Presiona ESC para cerrar", 
                               font=('Arial', 14), bg='#dc2626', fg='#fca5a5')
        escape_label.pack(side='bottom', pady=30)
        
        # Bind de tecla ESC para cerrar
        alert.bind('<Escape>', lambda e: alert.destroy())
        alert.focus_set()
        
        # Countdown autom√°tico
        countdown_time = 10
        def update_countdown():
            nonlocal countdown_time
            if countdown_time > 0:
                countdown_label.config(text=f"Se cerrar√° autom√°ticamente en {countdown_time} segundos")
                countdown_time -= 1
                alert.after(1000, update_countdown)
            else:
                alert.destroy()
        
        update_countdown()
        
        # Efecto de parpadeo sutil del t√≠tulo
        def blink_title():
            if alert.winfo_exists():
                current_color = title_label.cget('fg')
                new_color = '#fef2f2' if current_color == 'white' else 'white'
                title_label.config(fg=new_color)
                alert.after(800, blink_title)
        
        blink_title()
        
        # Reiniciar timer
        self.detection_start_time = time.time()
        print("üö® ALERTA PANTALLA COMPLETA MOSTRADA")
    
    def update_ui(self):
        """Actualizar interfaz"""
        if not self.is_monitoring:
            return
        
        # Timer
        if self.detection_start_time:
            elapsed = time.time() - self.detection_start_time
            minutes = int(elapsed // 60)
            seconds = int(elapsed % 60)
            self.timer_label.config(text=f"Tiempo: {minutes:02d}:{seconds:02d}")
            
            remaining = self.alert_time_var.get() - elapsed
            if remaining <= 5:
                self.status_label.config(text="Estado: ‚ö†Ô∏è CASI L√çMITE", fg='#f56565')
            else:
                self.status_label.config(text="Estado: üì± DETECTANDO USO", fg='#f6ad55')
        else:
            self.status_label.config(text="Estado: üëÄ Monitoreando...", fg='#4299e1')
        
        # Estad√≠sticas
        usage_minutes = int(self.stats['total_usage_today'] / 60)
        self.usage_today_label.config(text=f"üì± Uso total: {usage_minutes} min")
        self.sessions_label.config(text=f"üìÖ Sesiones: {len(self.stats['sessions'])}")
        self.alerts_label.config(text=f"üö® Alertas: {self.stats['alerts_triggered']}")
        
        # Info de detecci√≥n en tiempo real
        self.faces_label.config(text=f"üë§ Caras: {self.detection_data['faces_count']}")
        self.phones_label.config(text=f"üì± Celulares: {self.detection_data['phone_candidates']}")
        self.hands_label.config(text=f"üñêÔ∏è Regiones mano: {self.detection_data['hand_regions']}")
        self.motion_label.config(text=f"üèÉ Movimiento: {self.detection_data['motion_level']:.1f}%")
        
        # Actualizar config din√°micamente
        self.config['phone_distance_threshold'] = self.phone_distance_var.get()
        
        self.root.after(100, self.update_ui)
    
    def save_stats(self):
        """Guardar estad√≠sticas"""
        try:
            today = datetime.now().strftime('%Y-%m-%d')
            with open(f'phone_stats_optimized_{today}.json', 'w') as f:
                json.dump(self.stats, f, indent=2)
        except Exception as e:
            print(f"ERROR saving: {e}")
    
    def load_stats(self):
        """Cargar estad√≠sticas"""
        try:
            today = datetime.now().strftime('%Y-%m-%d')
            filename = f'phone_stats_optimized_{today}.json'
            if os.path.exists(filename):
                with open(filename, 'r') as f:
                    self.stats = json.load(f)
                print(f"Estad√≠sticas cargadas: {filename}")
        except Exception as e:
            print(f"ERROR loading: {e}")
    
    def run(self):
        """Ejecutar aplicaci√≥n"""
        try:
            self.root.protocol("WM_DELETE_WINDOW", self.on_closing)
            print("üöÄ Detector Optimizado iniciado")
            print("üí° Este detector NO requiere MediaPipe")
            print("‚úÖ Compatible con cualquier versi√≥n de Python")
            self.root.mainloop()
        except KeyboardInterrupt:
            print("\nCtrl+C detectado")
            self.stop_monitoring()
    
    def on_closing(self):
        """Cerrar aplicaci√≥n"""
        if self.is_monitoring:
            self.stop_monitoring()
        print("Aplicaci√≥n cerrada")
        self.root.destroy()

if __name__ == "__main__":
    import sys
    
    try:
        sys.stdout.reconfigure(encoding='utf-8')
    except:
        pass
    
    print("üî• DETECTOR OPTIMIZADO DE CELULAR")
    print("=" * 50)
    print("‚úÖ Funciona SIN MediaPipe")
    print("‚úÖ Compatible con Python 3.13")
    print("‚úÖ Detecci√≥n inteligente avanzada")
    print("Dependencias: pip install opencv-python numpy pygame pillow")
    print()
    
    try:
        detector = OptimizedPhoneDetector()
        detector.run()
    except ImportError as e:
        print(f"ERROR: Falta instalar: {e}")
        print("Ejecuta: pip install opencv-python numpy pygame pillow")
    except Exception as e:
        print(f"ERROR: {e}")